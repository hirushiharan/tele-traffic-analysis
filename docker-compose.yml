version: '3'
services:
  hadoop:
    build:
      context: .
      dockerfile: docker/Dockerfile-hadoop
    container_name: hadoop
    ports:
      - "9000:9000"
      - "8020:8020"
    environment:
      - HADOOP_VERSION=3.3.6
      - HADOOP_HOME=/opt/hadoop
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
      - HDFS_NAMENODE_USER=${HDFS_NAMENODE_USER}
      - HDFS_DATANODE_USER=${HDFS_DATANODE_USER}
      - HDFS_SECONDARYNAMENODE_USER=${HDFS_SECONDARYNAMENODE_USER}

  spark:
    build:
      context: .
      dockerfile: docker/Dockerfile-spark
    container_name: spark
    ports:
      - "4040:4040"
      - "7077:7077"
    depends_on:
      - hadoop

  mysql:
    image: mysql:8.0
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    ports:
      - "3307:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./docker/1_init_db.sql:/docker-entrypoint-initdb.d/1_init_db.sql
      - ./docker/2_create_views.sql:/docker-entrypoint-initdb.d/2_create_views.sql
    command: --max-allowed-packet=256M

  python-app:
    build:
      context: .
      dockerfile: docker/Dockerfile-python
    container_name: python-app
    ports:
      - "5000:5000"
    volumes:
      - .:/app
    depends_on:
      - mysql
      - spark

volumes:
  mysql_data:
